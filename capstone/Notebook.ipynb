{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "toggleable": false,
    "ulab": {
     "buttons": {
      "ulab-button-toggle-8acbb916": {
       "style": "primary"
      }
     }
    }
   },
   "source": [
    "# Udacity Nanodegree: Data Engineering - Capstone Project\n",
    "## ETL Pipeline for 2016 US Immigration Data\n",
    "\n",
    "### Project Summary\n",
    "This project describes and implements an ETL pipeline to create a database with a star schema representing data concerning immigration into the US in 2016.\n",
    "\n",
    "The pipeline, which runs on Apache Spark, ingests data of disparate types (including CSV and SAS binary) and outputs tables of cleaned and verified data into carefully modelled schemas in parquet files written to S3, as well as to the local disk.\n",
    "\n",
    "This allows BI and Data Scientist consumers to ingest and analyse the parquet-formatted data using the Spark cluster that performed the ETL, or using any other tool of their choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import configparser\n",
    "from datetime import datetime, timedelta\n",
    "from itertools import chain\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import DateType, FloatType, IntegerType, TimestampType\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('dl.cfg')\n",
    "\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = config['AWS']['KEY']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = config['AWS']['SECRET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder\\\n",
    "    .config('spark.jars.packages','saurfang:spark-sas7bdat:2.0.0-s_2.11,org.apache.hadoop:hadoop-aws:2.7.0') \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 1: Scope the Project and Gather Data\n",
    "\n",
    "### 1.1: Scope \n",
    "In this project, I will be transforming various disparate raw sources of data to create a clean, star-schema database stored in a cloud-based data lake to allow  analysis of data concerning people immigrating to the US using I-94 forms.\n",
    "\n",
    "I will be using [Apache Spark](https://spark.apache.org/) as my data-processing engine, writing [Parquet](https://parquet.apache.org/) files to [AWS S3](https://aws.amazon.com/s3/).\n",
    "\n",
    "### 1.2: Describe and Gather Data \n",
    "\n",
    "Overview:\n",
    "1. **I-94 Immigration Data**: this data comes from the [US National Tourism and Trade Office](https://travel.trade.gov/research/reports/i94/historical/2016.html), and has a row for every instance of a person immigrating to the US, showing information about each immigration (e.g., departure and arrival locations, visa type, etc.) \n",
    "  1. the core immigration data is a set of SAS binary files that are loaded onto an attached disk to the Spark Cluster on which this notebook is run - each file is of the form `i94_<month>16_sub.sas7bdat`\n",
    "  2. an ancillary SAS file (`source/I94_SAS_Labels_Description.SAS`) contains schema information about the core data\n",
    "2. **World Temperature Data**: this data comes from [Kaggle](https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data) and shows the average temperature per city per month\n",
    "3. **U.S. City Demographic Data**: this data comes from [OpenSoft](https://public.opendatasoft.com/explore/dataset/us-cities-demographics/export/) and shows the demographics (e.g., population by gender, ethnicity etc.) of US cities\n",
    "4. **Airport Data**: this data comes from [datahub.io](https://datahub.io/core/airport-codes#data) and is a simple table of airport codes and corresponding cities\n",
    "5. **ISO-3166 Countries Data**: this data comes (copy-pasted) from [IBAN](https://www.iban.com/country-codes) and shows the ISO 3166 codes for countries\n",
    "6. **US State Names Data**: this data comes (copy-pasted) from [yourdictionary.com](https://abbreviations.yourdictionary.com/articles/state-abbrev.html) and shows the standard names and abbreviations for the 50 US States\n",
    "\n",
    "Below, each data source is imported, the first 5 rows of each source printed, and a data dictionary (using the results of `.printSchema()` along with with best-attempt field descriptions from the data sources) displayed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 1.2.1: I-94 Immigration Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Load I-94 immigration data subset (April 2016) into pandas for initial data exploration\n",
    "fname_i94immigration = '../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat'\n",
    "df_spark_i94immigration_raw = spark.read.format('com.github.saurfang.sas.spark') \\\n",
    "    .load(fname_i94immigration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>XXX</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>U</td>\n",
       "      <td>None</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>10282016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.897628e+09</td>\n",
       "      <td>None</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Y</td>\n",
       "      <td>None</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>D/S</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3.736796e+09</td>\n",
       "      <td>00296</td>\n",
       "      <td>F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>WAS</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MI</td>\n",
       "      <td>20691.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>OS</td>\n",
       "      <td>6.666432e+08</td>\n",
       "      <td>93</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode i94addr  \\\n",
       "0    6.0  2016.0     4.0   692.0   692.0     XXX  20573.0      NaN    None   \n",
       "1    7.0  2016.0     4.0   254.0   276.0     ATL  20551.0      1.0      AL   \n",
       "2   15.0  2016.0     4.0   101.0   101.0     WAS  20545.0      1.0      MI   \n",
       "3   16.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "4   17.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "\n",
       "   depdate   ...     entdepu  matflag  biryear   dtaddto gender insnum  \\\n",
       "0      NaN   ...           U     None   1979.0  10282016   None   None   \n",
       "1      NaN   ...           Y     None   1991.0       D/S      M   None   \n",
       "2  20691.0   ...        None        M   1961.0  09302016      M   None   \n",
       "3  20567.0   ...        None        M   1988.0  09302016   None   None   \n",
       "4  20567.0   ...        None        M   2012.0  09302016   None   None   \n",
       "\n",
       "  airline        admnum  fltno visatype  \n",
       "0    None  1.897628e+09   None       B2  \n",
       "1    None  3.736796e+09  00296       F1  \n",
       "2      OS  6.666432e+08     93       B2  \n",
       "3      AA  9.246846e+10  00199       B2  \n",
       "4      AA  9.246846e+10  00199       B2  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark_i94immigration_raw.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Data dictionary:\n",
    "\n",
    "| Column   | Type   | Description |\n",
    "| -------- | ------ | ----------- |\n",
    "| cicid    | double | ID of Immigration |\n",
    "| i94yr    | double | Year of immigration (as: 4 digit e.g., 2020) |\n",
    "| i94mon   | double | Month of immigration (as: numeric, 1-based since April is 4.0) |\n",
    "| i94cit   | double | Country of citizenship (as: 3 digit code) |\n",
    "| i94res   | double | Country of citizenship (as: 3 digit code) |\n",
    "| i94port  | string | Port of entry (as: 3 letter code)\n",
    "| arrdate  | double | Date of arrival (as: seconds since 1/1/1960) |\n",
    "| i94mode  | double | Mode of travel (as: 1 = Air, 2 = Sea, 3 = Land, 9 = Not Reported) |\n",
    "| i94addr  | string | State of entry (as: 2 letter code, e.g., CA for California) |\n",
    "| depdate  | double | Date of arrival (as: seconds since 1/1/1960) |\n",
    "| i94bir   | double | Age (in years) |\n",
    "| i94visa  | double | Visa code (as: 1 = Business, 2 = Pleasure, 3 = Student) |\n",
    "| count    | double | Used for summary statistics |\n",
    "| dtadfile | string | Character Date Field - Date added to I-94 Files |\n",
    "| visapost | string | Department of State where where Visa was issued |\n",
    "| occup    | string | Occupation that will be performed in U.S. |\n",
    "| entdepa  | string | Arrival Flag - admitted or paroled into the U.S. |\n",
    "| entdepd  | string | Departure Flag - Departed, lost I-94 or is deceased |\n",
    "| entdepu  | string | Update Flag - Either apprehended, overstayed, adjusted to perm residence |\n",
    "| matflag  | string | Match flag - Match of arrival and departure records |\n",
    "| biryear  | double | Year of birth (as: 4 digits) |\n",
    "| dtaddto  | string | Character Date Field - Date to which admitted to U.S. (allowed to stay until) |\n",
    "| gender   | string | Non-immigrant sex |\n",
    "| insnum   | string | INS number |\n",
    "| airline  | string | Airline used to arrive in U.S. |\n",
    "| admnum   | double | Admission Number |\n",
    "| fltno    | string | Flight number of Airline used to arrive in U.S. |\n",
    "| visatype | string | Class of admission legally admitting the non-immigrant to temporarily stay in U.S. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 1.2.2: World Temperature Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "fname_worldtemperature = '../../data2/GlobalLandTemperaturesByCity.csv'\n",
    "df_spark_worldtemperature_raw = spark.read.format('csv') \\\n",
    "    .option('header', 'true').option('sep', ',') \\\n",
    "    .load(fname_worldtemperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.7369999999999999</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743-12-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744-01-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1744-02-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744-03-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt AverageTemperature AverageTemperatureUncertainty   City  \\\n",
       "0  1743-11-01              6.068            1.7369999999999999  Århus   \n",
       "1  1743-12-01               None                          None  Århus   \n",
       "2  1744-01-01               None                          None  Århus   \n",
       "3  1744-02-01               None                          None  Århus   \n",
       "4  1744-03-01               None                          None  Århus   \n",
       "\n",
       "   Country Latitude Longitude  \n",
       "0  Denmark   57.05N    10.33E  \n",
       "1  Denmark   57.05N    10.33E  \n",
       "2  Denmark   57.05N    10.33E  \n",
       "3  Denmark   57.05N    10.33E  \n",
       "4  Denmark   57.05N    10.33E  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark_worldtemperature_raw.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Data dictionary:\n",
    "\n",
    "| Column                        | Type   | Description |\n",
    "| ----------------------------- | ------ | ----------- |\n",
    "| dt                            | string | Date of record, always the first of a month (as: YYYY-MM-DD) |\n",
    "| AverageTemperature            | string | Average temperature of city for that month (as: Celsius) |\n",
    "| AverageTemperatureUncertainty | string | The 95% confidence interval around the average\n",
    "| City                          | string | City |\n",
    "| Country                       | string | Country of the city |\n",
    "| Latitude                      | string | Latitude of the city (as: \\<decimal degrees north\\>N ) |\n",
    "| Longitude                     | string | Longitude of the city (as: \\<decimal degrees east\\>E ) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 1.2.3: U.S. City Demographic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "fname_uscitydemographic = 'source/us-cities-demographics.csv'\n",
    "df_spark_uscitydemographic_raw = spark.read.format('csv') \\\n",
    "    .option('header', 'true') \\\n",
    "    .option('sep', ';') \\\n",
    "    .load(fname_uscitydemographic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601</td>\n",
       "      <td>41862</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562</td>\n",
       "      <td>30908</td>\n",
       "      <td>2.6</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129</td>\n",
       "      <td>49500</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147</td>\n",
       "      <td>32935</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040</td>\n",
       "      <td>46799</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819</td>\n",
       "      <td>8229</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127</td>\n",
       "      <td>87105</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821</td>\n",
       "      <td>33878</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040</td>\n",
       "      <td>143873</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829</td>\n",
       "      <td>86253</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City          State Median Age Male Population  \\\n",
       "0     Silver Spring       Maryland       33.8           40601   \n",
       "1            Quincy  Massachusetts       41.0           44129   \n",
       "2            Hoover        Alabama       38.5           38040   \n",
       "3  Rancho Cucamonga     California       34.5           88127   \n",
       "4            Newark     New Jersey       34.6          138040   \n",
       "\n",
       "  Female Population Total Population Number of Veterans Foreign-born  \\\n",
       "0             41862            82463               1562        30908   \n",
       "1             49500            93629               4147        32935   \n",
       "2             46799            84839               4819         8229   \n",
       "3             87105           175232               5821        33878   \n",
       "4            143873           281913               5829        86253   \n",
       "\n",
       "  Average Household Size State Code                       Race  Count  \n",
       "0                    2.6         MD         Hispanic or Latino  25924  \n",
       "1                   2.39         MA                      White  58723  \n",
       "2                   2.58         AL                      Asian   4759  \n",
       "3                   3.18         CA  Black or African-American  24437  \n",
       "4                   2.73         NJ                      White  76402  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark_uscitydemographic_raw.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Data dictionary:\n",
    "\n",
    "| Column                 | Type   | Description |\n",
    "| ---------------------- | ------ | ----------- |\n",
    "| City                   | string | City |\n",
    "| State                  | string | State in which the city is located |\n",
    "| Median Age             | string | Median age of residents of the city (as: years) |\n",
    "| Male Population        | string | Count of males in the city |\n",
    "| Female Population      | string | Count of females in the city |\n",
    "| Total Population       | string | Count of people in the city |\n",
    "| Number of Veterans     | string | Count of veterans in the city |\n",
    "| Foreign-born           | string | Count of foreign-born people in the city |\n",
    "| Average Household Size | string | Mean household size in the city |\n",
    "| State Code             | string | State in which the city is located (as: 2 letter code) |\n",
    "| Race                   | string | A race (e.g., \"Hispanic or Latino\") |\n",
    "| Count                  | string | The number of people of the given race in the city |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 1.2.4: Airport Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "fname_airport = 'source/airport-codes_csv.csv'\n",
    "df_spark_airport_raw = spark.read.format('csv') \\\n",
    "    .option('header', 'true').option('sep', ',') \\\n",
    "    .load(fname_airport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>11</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>00A</td>\n",
       "      <td>None</td>\n",
       "      <td>00A</td>\n",
       "      <td>-74.93360137939453, 40.07080078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>3435</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>00AA</td>\n",
       "      <td>None</td>\n",
       "      <td>00AA</td>\n",
       "      <td>-101.473911, 38.704022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>450</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>00AK</td>\n",
       "      <td>None</td>\n",
       "      <td>00AK</td>\n",
       "      <td>-151.695999146, 59.94919968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>820</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AL</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>00AL</td>\n",
       "      <td>None</td>\n",
       "      <td>00AL</td>\n",
       "      <td>-86.77030181884766, 34.86479949951172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00AR</td>\n",
       "      <td>closed</td>\n",
       "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
       "      <td>237</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AR</td>\n",
       "      <td>Newport</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-91.254898, 35.6087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                                name elevation_ft  \\\n",
       "0   00A       heliport                   Total Rf Heliport           11   \n",
       "1  00AA  small_airport                Aero B Ranch Airport         3435   \n",
       "2  00AK  small_airport                        Lowell Field          450   \n",
       "3  00AL  small_airport                        Epps Airpark          820   \n",
       "4  00AR         closed  Newport Hospital & Clinic Heliport          237   \n",
       "\n",
       "  continent iso_country iso_region  municipality gps_code iata_code  \\\n",
       "0        NA          US      US-PA      Bensalem      00A      None   \n",
       "1        NA          US      US-KS         Leoti     00AA      None   \n",
       "2        NA          US      US-AK  Anchor Point     00AK      None   \n",
       "3        NA          US      US-AL       Harvest     00AL      None   \n",
       "4        NA          US      US-AR       Newport     None      None   \n",
       "\n",
       "  local_code                            coordinates  \n",
       "0        00A     -74.93360137939453, 40.07080078125  \n",
       "1       00AA                 -101.473911, 38.704022  \n",
       "2       00AK            -151.695999146, 59.94919968  \n",
       "3       00AL  -86.77030181884766, 34.86479949951172  \n",
       "4       None                    -91.254898, 35.6087  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark_airport_raw.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Data dictionary:\n",
    "\n",
    "| Column       | Type   | Description |\n",
    "| ------------ | ------ | ----------- |\n",
    "| ident        | string | Airport code (as: ICAO or IATA format) |\n",
    "| type         | string | Type of airport (as one of: large_airport, balloonport, seaplane_base, heliport, closed, medium_airport, small_airport) |\n",
    "| name         | string | Name of airport |\n",
    "| elevation_ft | string | Elevation of airport, in feet (as: feet) |\n",
    "| continent    | string | Continent in which the airport is located (as one of: NA, SA, AS, AN, OC, EU, AF) |\n",
    "| iso_country  | string | Country in which the airport is located (as: ISO-3166 format) |\n",
    "| iso_region   | string | Region in which the airport is located (as: ISO-3166 format) |\n",
    "| municipality | string | City in which the airport is located |\n",
    "| gps_code     | string | GPS code of the airport |\n",
    "| iata_code    | string | Airport code (as: IATA format)\n",
    "| local_code   | string | Local code of the airport |\n",
    "| coordinates  | string | Coordinates of the airport (as: \\<decimal degrees latitude\\>, \\<decimal degrees longitude\\>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "This data will not be used further in the project, as there are no columns that can be joined with any of the other tables. (Note: `i94port` in the _I-94 Immigration Data_ does **not** correspond to either `ident` or `iata_code` in the _Airport Data_.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 1.2.5: ISO-3166 Countries Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "fname_iso3166countries = 'source/iso-3166-countries.csv'\n",
    "df_spark_iso3166countries_raw = spark.read.format('csv') \\\n",
    "    .option('header', 'true').option('sep', '\\t') \\\n",
    "    .load(fname_iso3166countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Alpha-2 code</th>\n",
       "      <th>Alpha-3 code</th>\n",
       "      <th>Numeric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AF</td>\n",
       "      <td>AFG</td>\n",
       "      <td>004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>AL</td>\n",
       "      <td>ALB</td>\n",
       "      <td>008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>DZ</td>\n",
       "      <td>DZA</td>\n",
       "      <td>012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>American Samoa</td>\n",
       "      <td>AS</td>\n",
       "      <td>ASM</td>\n",
       "      <td>016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>AD</td>\n",
       "      <td>AND</td>\n",
       "      <td>020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Country Alpha-2 code Alpha-3 code Numeric\n",
       "0     Afghanistan           AF          AFG     004\n",
       "1         Albania           AL          ALB     008\n",
       "2         Algeria           DZ          DZA     012\n",
       "3  American Samoa           AS          ASM     016\n",
       "4         Andorra           AD          AND     020"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark_iso3166countries_raw.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Data dictionary:\n",
    "\n",
    "| Column       | Type   | Description |\n",
    "| ------------ | ------ | ----------- |\n",
    "| Country      | string | Country name |\n",
    "| Alpha-2 code | string | Country code (as: 2 character code) |\n",
    "| Alpha-3 code | string | Country code (as: 3 character code) |\n",
    "| Numeric      | string | Country code (as: 3 digits) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 1.2.6: US States Names Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "fname_usstatesnames = 'source/us-states.csv'\n",
    "df_spark_usstatesnames_raw = spark.read.format('csv') \\\n",
    "    .option('header', 'true').option('sep', '-') \\\n",
    "    .load(fname_usstatesnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>AR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Name Code\n",
       "0     Alabama   AL\n",
       "1      Alaska   AK\n",
       "2     Arizona   AZ\n",
       "3    Arkansas   AR\n",
       "4  California   CA"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark_usstatesnames_raw.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Data dictionary:\n",
    "\n",
    "| Column | Type   | Description |\n",
    "| ------ | ------ | ----------- |\n",
    "| Name   | string | State name |\n",
    "| Code   | string | State code (as: 2 character code) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 2: Explore and Assess the Data\n",
    "### 2.1: Explore the Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 2.1.1: I-94 Immigration Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_spark_i94immigration = df_spark_i94immigration_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The _I-94 Immigration_ does not contain any duplicate rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark_i94immigration.count() == df_spark_i94immigration.dropDuplicates().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "However, some columns have:\n",
    "1. definitions/values that are not well explained/understood\n",
    " 1. the meanings of the `count`, `dtadfile`, `visapost`, `occup`, `entdepa`, `entdepd`, `entdepu`, `matflag`, `dtaddto`, `insnum`, `admnum` are not well explained/understood, so these columns should be removed\n",
    "2. unsuitable types\n",
    " 1. integer: the columns `cicid`, `i94yr`, `i94mon`, `i94mode`, `i94bir`, `i94visa`, `biryear` should be of `IntegerType`\n",
    " 2. date: the columns `arrdate`, `depdate` should be of `DateType`\n",
    " 3. string (enum): the columns `i94mode` and `i94visa` should be of `StringType` (using their enumerated values from `source/I94__SAS_Labels_Description.SAS`)\n",
    "3. non-standard formats\n",
    " 1. iso-3166: the columns `i94cit` and `i94res` are in a non-standard format, and should be coverted to `ISO-3166: Alpha-3` format\n",
    "4. invalid values\n",
    " 1. states: the column `i94addr` has values that are not valid US states\n",
    "5. unsemantic names\n",
    " 1. many of the columns have names that are hard to understand\n",
    "6. redundant data\n",
    " 1. the `i94yr` and `i94mon` columns are made redundant by the `arrdate` column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 2.1.2: World Temperature Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_spark_worldtemperature = df_spark_worldtemperature_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The _World Temperature Data_ does not contain any duplicate rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark_worldtemperature.count() == df_spark_worldtemperature.dropDuplicates().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "However, some columns have:\n",
    "1. unsuitable types\n",
    " 1. integer: the columns `AverageTemperature`, `AverageTemperatureUncertainty` should be of IntegerType\n",
    " 2. date: the column `dt` should be of DateType\n",
    "2. non-standard formats\n",
    " 1. iso-3166: the column `Country` is in a non-standard format, and should be coverted to `ISO-3166: Alpha-3`\n",
    "3. unsemantic names\n",
    " 1. the column naming is not always clear (e.g., `dt` means `Date`)\n",
    "4. out-of-range data\n",
    " 1. the date range of this data is 1743-2013, so we cannot match this data with the core immigration dataset by date (since it is 2016); therefore, an average over time (e.g., average over the 20 year period from 1993-2013) per city is suitable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 2.1.3: U.S. City Demographic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_spark_uscitydemographic = df_spark_uscitydemographic_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The _U.S. City Demographic Data_ does not contain any duplicate rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark_uscitydemographic.count() == df_spark_uscitydemographic.dropDuplicates().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "However, some columns have:\n",
    "1. unsuitable types\n",
    " 1. integer: the columns `Male Population`, `Female Population`, `Total Population`, `Number of Veterans`, `Foreign-born`, `Count` should be of `IntegerType`\n",
    " 2. float: the columns `Median Age`, `Average Household Size`  should be of `DateType`\n",
    "2. unsemantic names\n",
    " 1. the naming convention is not consistent across the columns\n",
    "3. redundant data\n",
    "  1. every row for a given city has identical data in all columns except `Race` and `Count`, so the table can be pivoted to have only one row per city and a column containing the population count for each race"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 2.1.4: ISO-3166 Countries Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_spark_iso3166countries = df_spark_iso3166countries_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The _ISO-3166 Countries Data_ does not contain any duplicate rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark_iso3166countries.count() == df_spark_iso3166countries.dropDuplicates().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "or any other issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 2.1.5: US States Names Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_spark_usstatesnames = df_spark_usstatesnames_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The _US States Names_ does not contain any duplicate rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark_usstatesnames.count() == df_spark_usstatesnames.dropDuplicates().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 2.2: Cleaning the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 2.2.1: I-94 Immigration Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 2.2.1.1: Definitions/values that are not well explained/understood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "unneeded_columns = [\n",
    "    'count', 'dtadfile', 'visapost', 'occup', 'entdepa', 'entdepd', 'entdepu', 'matflag', 'dtaddto', 'insnum', 'admnum',\n",
    "]\n",
    "df_spark_i94immigration = df_spark_i94immigration.drop(*unneeded_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 2.2.1.2: Unsuitable types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# columns that should be IntegerType\n",
    "integer_type_columns = [\n",
    "    'cicid', 'i94yr', 'i94mon', 'i94mode', 'i94bir', 'i94visa', 'biryear',\n",
    "    'i94cit', 'i94res', # note - these two will be further converted in 2.2.1.3\n",
    "]\n",
    "for column in df_spark_i94immigration.columns:\n",
    "    if column in integer_type_columns:\n",
    "        df_spark_i94immigration = df_spark_i94immigration \\\n",
    "            .withColumn(column, df_spark_i94immigration[column].cast(IntegerType()))\n",
    "\n",
    "# columns that should be DateType\n",
    "udf_date_from_sas = F.udf(lambda x: x if x is None else (datetime(1960, 1, 1) + timedelta(days=x)), DateType())\n",
    "date_type_columns = [\n",
    "    'arrdate', 'depdate',\n",
    "]\n",
    "for column in df_spark_i94immigration.columns:\n",
    "    if column in date_type_columns:\n",
    "        df_spark_i94immigration = df_spark_i94immigration \\\n",
    "            .withColumn(column, udf_date_from_sas(df_spark_i94immigration[column]))\n",
    "\n",
    "# columns that should be string enums (for readability)\n",
    "mapping_i94mode_expr = F.create_map(\n",
    "    [F.lit(x) for x in chain(*({ 1: 'Air', 2: 'Sea', 3: 'Land', 9: 'Not Reported' }).items())]\n",
    ")\n",
    "mapping_i94visa_expr = F.create_map(\n",
    "    [F.lit(x) for x in chain(*({ 1: 'Business', 2: 'Pleasure', 3: 'Student' }).items())]\n",
    ")\n",
    "\n",
    "df_spark_i94immigration = df_spark_i94immigration \\\n",
    "    .withColumn('i94mode', mapping_i94mode_expr.getItem(F.col('i94mode'))) \\\n",
    "    .withColumn('i94visa', mapping_i94visa_expr.getItem(F.col('i94visa')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 2.2.1.3: Non-standard formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I94 name</th>\n",
       "      <th>I94 code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MEXICO Air Sea, and Not Reported (I-94, no lan...</td>\n",
       "      <td>582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFGHANISTAN</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALBANIA</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALGERIA</td>\n",
       "      <td>316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ANDORRA</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            I94 name  I94 code\n",
       "0  MEXICO Air Sea, and Not Reported (I-94, no lan...       582\n",
       "1                                        AFGHANISTAN       236\n",
       "2                                            ALBANIA       101\n",
       "3                                            ALGERIA       316\n",
       "4                                            ANDORRA       102"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## transform i94cit and i94res columns into the ISO-3166 Alpha-3 format (in steps (a), (b) and (c) below)\n",
    "\n",
    "# a)\n",
    "# create mapping from: I94 name -> I94 code i94cit/i94res -> country name\n",
    "# (where I94 code is the format of the i94cit/i94res columns)\n",
    "# by parsing source/I94_SAS_Labels_Descriptions\n",
    "\n",
    "fname_saslabels_raw = 'source/I94_SAS_Labels_Descriptions.SAS'\n",
    "df_spark_saslabels_raw = spark.read.text(fname_saslabels_raw)\n",
    "\n",
    "data = []\n",
    "has_seen_value_i94cntyl = False\n",
    "for row in df_spark_saslabels_raw.collect():\n",
    "    value = row.value\n",
    "    if (not has_seen_value_i94cntyl) and ('i94cntyl' in value):\n",
    "        has_seen_value_i94cntyl = True\n",
    "        continue\n",
    "    if has_seen_value_i94cntyl and (not value.strip()):\n",
    "        break\n",
    "    if has_seen_value_i94cntyl:\n",
    "        data.append((\n",
    "            value.split('=')[1].strip().strip(';').strip().strip('\\'').strip(),\n",
    "            value.split('=')[0].strip()\n",
    "        ))\n",
    "df_spark_i94countries = spark.createDataFrame(data, ['I94 name', 'I94 code'])\n",
    "df_spark_i94countries = df_spark_i94countries \\\n",
    "    .withColumn('I94 code', df_spark_i94countries['I94 code'].cast(IntegerType()))\n",
    "\n",
    "df_spark_i94countries.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Alpha-3 code</th>\n",
       "      <th>I94 code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aruba</td>\n",
       "      <td>ABW</td>\n",
       "      <td>532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Angola</td>\n",
       "      <td>AGO</td>\n",
       "      <td>324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anguilla</td>\n",
       "      <td>AIA</td>\n",
       "      <td>529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Country Alpha-3 code  I94 code\n",
       "0        Aruba          ABW       532\n",
       "1  Afghanistan          AFG       236\n",
       "2       Angola          AGO       324\n",
       "3     Anguilla          AIA       529"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# b)\n",
    "# create mapping from: I94 code -> Alpha-3 code\n",
    "# (where I94 code is the format of the i94cit/i94res columns, and Alpha-3 code is an ISO-3166 standard)\n",
    "\n",
    "# i)\n",
    "# create a 'Country (normalized)' column in df_spark_iso3166countries to more closely resemble the format \n",
    "# of the 'i94_country_name' column in df_spark_i94countries\n",
    "df_spark_iso3166countries = df_spark_iso3166countries \\\n",
    "    .withColumn('Country (normalized)', F.upper(df_spark_iso3166countries['Country']))\n",
    "df_spark_iso3166countries = df_spark_iso3166countries \\\n",
    "    .withColumn('Country (normalized)', F.regexp_replace(df_spark_iso3166countries['Country (normalized)'], '[\\(\\[].*?[\\)\\]]', ''))\n",
    "df_spark_iso3166countries = df_spark_iso3166countries \\\n",
    "    .withColumn('Country (normalized)', F.regexp_replace(df_spark_iso3166countries['Country (normalized)'], '[ \\t]+$', ''))\n",
    "\n",
    "# ii)\n",
    "# perform manual replacements on countries that haven't found a match\n",
    "# the manual task of populating this list (of 58 countries) can be completed by comparing:\n",
    "#  the value in the 'Country' column of the rows in df_spark_country_map that have i94_code None, with\n",
    "#  the closest corresponding value in the 'I94_country_name' column in df_spark_i94countries\n",
    "manual_replace_list = [\n",
    "    ('ANTIGUA AND BARBUDA', 'ANTIGUA-BARBUDA'),\n",
    "    # ...\n",
    "    ('CHINA', 'CHINA, PRC'),\n",
    "    # ...\n",
    "    ('MEXICO', 'MEXICO Air Sea, and Not Reported (I-94, no land arrivals)'),\n",
    "    # ...\n",
    "    ('UNITED KINGDOM OF GREAT BRITAIN AND NORTHERN IRELAND', 'UNITED KINGDOM'),\n",
    "    # ... etc...\n",
    "]\n",
    "for k,v in manual_replace_list:\n",
    "    df_spark_iso3166countries = df_spark_iso3166countries.replace(k, v, 'Country (normalized)')\n",
    "\n",
    "# iii)\n",
    "# join df_spark_iso3166countries and df_spark_i94countries\n",
    "df_spark_countries = df_spark_iso3166countries.join(\n",
    "    df_spark_i94countries,\n",
    "    df_spark_iso3166countries['Country (normalized)'] == df_spark_i94countries['I94 name'],\n",
    "    how='left',\n",
    ")\n",
    "\n",
    "df_spark_countries.select('Country', 'Alpha-3 code', 'I94 code').sort(F.asc('Alpha-3 code')).limit(4).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>i94bir</th>\n",
       "      <th>i94visa</th>\n",
       "      <th>biryear</th>\n",
       "      <th>gender</th>\n",
       "      <th>airline</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>ECU</td>\n",
       "      <td>ECU</td>\n",
       "      <td>XXX</td>\n",
       "      <td>2016-04-29</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>37</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>1979</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ATL</td>\n",
       "      <td>2016-04-07</td>\n",
       "      <td>Air</td>\n",
       "      <td>AL</td>\n",
       "      <td>None</td>\n",
       "      <td>25</td>\n",
       "      <td>Student</td>\n",
       "      <td>1991</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>00296</td>\n",
       "      <td>F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>ALB</td>\n",
       "      <td>ALB</td>\n",
       "      <td>WAS</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>Air</td>\n",
       "      <td>MI</td>\n",
       "      <td>2016-08-25</td>\n",
       "      <td>55</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>1961</td>\n",
       "      <td>M</td>\n",
       "      <td>OS</td>\n",
       "      <td>93</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>ALB</td>\n",
       "      <td>ALB</td>\n",
       "      <td>NYC</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>Air</td>\n",
       "      <td>MA</td>\n",
       "      <td>2016-04-23</td>\n",
       "      <td>28</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>1988</td>\n",
       "      <td>None</td>\n",
       "      <td>AA</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>ALB</td>\n",
       "      <td>ALB</td>\n",
       "      <td>NYC</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>Air</td>\n",
       "      <td>MA</td>\n",
       "      <td>2016-04-23</td>\n",
       "      <td>4</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>2012</td>\n",
       "      <td>None</td>\n",
       "      <td>AA</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cicid  i94yr  i94mon i94cit i94res i94port     arrdate i94mode i94addr  \\\n",
       "0      6   2016       4    ECU    ECU     XXX  2016-04-29    None    None   \n",
       "1      7   2016       4   None   None     ATL  2016-04-07     Air      AL   \n",
       "2     15   2016       4    ALB    ALB     WAS  2016-04-01     Air      MI   \n",
       "3     16   2016       4    ALB    ALB     NYC  2016-04-01     Air      MA   \n",
       "4     17   2016       4    ALB    ALB     NYC  2016-04-01     Air      MA   \n",
       "\n",
       "      depdate  i94bir   i94visa  biryear gender airline  fltno visatype  \n",
       "0        None      37  Pleasure     1979   None    None   None       B2  \n",
       "1        None      25   Student     1991      M    None  00296       F1  \n",
       "2  2016-08-25      55  Pleasure     1961      M      OS     93       B2  \n",
       "3  2016-04-23      28  Pleasure     1988   None      AA  00199       B2  \n",
       "4  2016-04-23       4  Pleasure     2012   None      AA  00199       B2  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# c)\n",
    "# replace i94cit and i94res df_spark_i94immigration with ISO-3166 Alpha-3 codes\n",
    "i94immigration_column_names = df_spark_i94immigration.columns\n",
    "\n",
    "def replace_i94_code_with_iso3166(\n",
    "    column_name,\n",
    "):\n",
    "    global df_spark_i94immigration\n",
    "    global df_spark_countries\n",
    "    df_spark_i94immigration = df_spark_i94immigration.join(\n",
    "        df_spark_countries,\n",
    "        df_spark_i94immigration[column_name] == df_spark_countries['I94 code'],\n",
    "        how='left'\n",
    "    ).drop(\n",
    "        column_name\n",
    "    ).withColumnRenamed(\n",
    "        'Alpha-3 code', column_name\n",
    "    ).select(*i94immigration_column_names)\n",
    "\n",
    "replace_i94_code_with_iso3166('i94cit')\n",
    "replace_i94_code_with_iso3166('i94res')\n",
    "\n",
    "df_spark_i94immigration = df_spark_i94immigration.sort(F.asc('cicid'))\n",
    "\n",
    "df_spark_i94immigration.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 2.2.1.4: Invalid values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# set the value of i94addr to None if it is not a valid US state\n",
    "states = df_spark_usstatesnames.select('Code').toPandas()['Code']\n",
    "df_spark_i94immigration = df_spark_i94immigration.withColumn(\n",
    "    'i94addr',\n",
    "    F.when(\n",
    "        F.col('i94addr').isin(*states),\n",
    "        F.col('i94addr')\n",
    "    ).otherwise(None)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 2.2.1.5: Unsemantic names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "column_rename = [\n",
    "    ('cicid', 'Id'),\n",
    "    ('i94yr', 'Year'),\n",
    "    ('i94mon', 'Month'),\n",
    "    ('i94cit', 'Country Citizenship)'),\n",
    "    ('i94res', 'Country Residence)'),\n",
    "    ('i94port', 'Port Of Arrival'),\n",
    "    ('arrdate', 'Date Of Arrival'),\n",
    "    ('i94mode', 'Mode Of Travel'),\n",
    "    ('i94addr', 'State Of Arrival'),\n",
    "    ('depdate', 'Date Of Departure'),\n",
    "    ('i94bir', 'Age'),\n",
    "    ('i94visa', 'Visa Category'),\n",
    "    ('biryear', 'Year Of Birth'),\n",
    "    ('gender', 'Gender'),\n",
    "    ('airline', 'Airline'),\n",
    "    ('fltno', 'Flight Number'),\n",
    "    ('visatype', 'Visa Type'),\n",
    "]\n",
    "\n",
    "for k,v in column_rename:\n",
    "    df_spark_i94immigration = df_spark_i94immigration.withColumnRenamed(k, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 2.2.1.6: Redundant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "redundant_columns = ['Year', 'Month']\n",
    "\n",
    "for column in redundant_columns:\n",
    "    df_spark_i94immigration = df_spark_i94immigration.drop(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Country Citizenship)</th>\n",
       "      <th>Country Residence)</th>\n",
       "      <th>Port Of Arrival</th>\n",
       "      <th>Date Of Arrival</th>\n",
       "      <th>Mode Of Travel</th>\n",
       "      <th>State Of Arrival</th>\n",
       "      <th>Date Of Departure</th>\n",
       "      <th>Age</th>\n",
       "      <th>Visa Category</th>\n",
       "      <th>Year Of Birth</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Airline</th>\n",
       "      <th>Flight Number</th>\n",
       "      <th>Visa Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>ECU</td>\n",
       "      <td>ECU</td>\n",
       "      <td>XXX</td>\n",
       "      <td>2016-04-29</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>37</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>1979</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ATL</td>\n",
       "      <td>2016-04-07</td>\n",
       "      <td>Air</td>\n",
       "      <td>AL</td>\n",
       "      <td>None</td>\n",
       "      <td>25</td>\n",
       "      <td>Student</td>\n",
       "      <td>1991</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>00296</td>\n",
       "      <td>F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>ALB</td>\n",
       "      <td>ALB</td>\n",
       "      <td>WAS</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>Air</td>\n",
       "      <td>MI</td>\n",
       "      <td>2016-08-25</td>\n",
       "      <td>55</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>1961</td>\n",
       "      <td>M</td>\n",
       "      <td>OS</td>\n",
       "      <td>93</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>ALB</td>\n",
       "      <td>ALB</td>\n",
       "      <td>NYC</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>Air</td>\n",
       "      <td>MA</td>\n",
       "      <td>2016-04-23</td>\n",
       "      <td>28</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>1988</td>\n",
       "      <td>None</td>\n",
       "      <td>AA</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>ALB</td>\n",
       "      <td>ALB</td>\n",
       "      <td>NYC</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>Air</td>\n",
       "      <td>MA</td>\n",
       "      <td>2016-04-23</td>\n",
       "      <td>4</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>2012</td>\n",
       "      <td>None</td>\n",
       "      <td>AA</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id Country Citizenship) Country Residence) Port Of Arrival Date Of Arrival  \\\n",
       "0   6                  ECU                ECU             XXX      2016-04-29   \n",
       "1   7                 None               None             ATL      2016-04-07   \n",
       "2  15                  ALB                ALB             WAS      2016-04-01   \n",
       "3  16                  ALB                ALB             NYC      2016-04-01   \n",
       "4  17                  ALB                ALB             NYC      2016-04-01   \n",
       "\n",
       "  Mode Of Travel State Of Arrival Date Of Departure  Age Visa Category  \\\n",
       "0           None             None              None   37      Pleasure   \n",
       "1            Air               AL              None   25       Student   \n",
       "2            Air               MI        2016-08-25   55      Pleasure   \n",
       "3            Air               MA        2016-04-23   28      Pleasure   \n",
       "4            Air               MA        2016-04-23    4      Pleasure   \n",
       "\n",
       "   Year Of Birth Gender Airline Flight Number Visa Type  \n",
       "0           1979   None    None          None        B2  \n",
       "1           1991      M    None         00296        F1  \n",
       "2           1961      M      OS            93        B2  \n",
       "3           1988   None      AA         00199        B2  \n",
       "4           2012   None      AA         00199        B2  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark_i94immigration.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 2.2.2: World Temperature Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 2.2.2.1: Unsuitable types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# columns that should be IntegerType\n",
    "integer_type_columns = [\n",
    "    'AverageTemperature', 'AverageTemperatureUncertainty',\n",
    "]\n",
    "for column in df_spark_worldtemperature.columns:\n",
    "    if column in integer_type_columns:\n",
    "        df_spark_worldtemperature = df_spark_worldtemperature \\\n",
    "            .withColumn(column, df_spark_worldtemperature[column].cast(IntegerType()))\n",
    "\n",
    "# columns that should be DateType\n",
    "udf_date_from_worldtemperature = F.udf(lambda x: datetime.strptime(x, '%Y-%m-%d'), DateType())\n",
    "date_type_columns = [\n",
    "    'dt',\n",
    "]\n",
    "for column in df_spark_worldtemperature.columns:\n",
    "    if column in date_type_columns:\n",
    "        df_spark_worldtemperature = df_spark_worldtemperature \\\n",
    "            .withColumn(column, udf_date_from_worldtemperature(df_spark_worldtemperature[column]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 2.2.2.2: Non-standard formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# transform Country column into the ISO-3166 Alpha-3 format\n",
    "worldtemperature_column_names = df_spark_worldtemperature.columns\n",
    "\n",
    "# manually transform countries whose names don't match up with the name in ISO-3166 standard\n",
    "worldtemperature_country_rename_dict = {\n",
    "    'Bahamas': 'Bahamas (the)',\n",
    "    'Bolivia': 'Bolivia (Plurinational State of)',\n",
    "    'Bosnia And Herzegovina': 'Bosnia and Herzegovina',\n",
    "    'Burma': 'Myanmar',\n",
    "    'Central African Republic': 'Central African Republic (the)',\n",
    "    'Congo': 'Congo (the)',\n",
    "    'Congo (Democratic Republic Of The)': 'Congo (the Democratic Republic of the)',\n",
    "    'Czech Republic': 'Czechia',\n",
    "    'Côte D\\'Ivoire': 'Côte d\\'Ivoire',\n",
    "    'Dominican Republic': 'Dominican Republic (the)',\n",
    "    'Gambia': 'Gambia (the)',\n",
    "    'Guinea Bissau': 'Guinea-Bissau',\n",
    "    'Iran': 'Iran (Islamic Republic of)',\n",
    "    'Laos': 'Lao People\\'s Democratic Republic (the)',\n",
    "    'Macedonia': 'Republic of North Macedonia',\n",
    "    'Moldova': 'Moldova (the Republic of)',\n",
    "    'Netherlands': 'Netherlands (the)',\n",
    "    'Niger': 'Niger (the)',\n",
    "    'Philippines': 'Philippines (the)',\n",
    "    'Reunion': 'Réunion',\n",
    "    'Russia': 'Russian Federation (the)',\n",
    "    'South Korea': 'Korea (the Republic of)',\n",
    "    'Sudan': 'Sudan (the)',\n",
    "    'Swaziland': 'Eswatini',\n",
    "    'Syria': 'Syrian Arab Republic',\n",
    "    'Taiwan': 'Taiwan (Province of China)',\n",
    "    'Tanzania': 'Tanzania, United Republic of',\n",
    "    'United Arab Emirates': 'United Arab Emirates (the)',\n",
    "    'United Kingdom': 'United Kingdom of Great Britain and Northern Ireland (the)',\n",
    "    'United States': 'United States of America (the)',\n",
    "    'Venezuela': 'Venezuela (Bolivarian Republic of)',\n",
    "    'Vietnam': 'Viet Nam',\n",
    "}\n",
    "df_spark_worldtemperature = df_spark_worldtemperature \\\n",
    "    .replace(worldtemperature_country_rename_dict, 1, 'Country')\n",
    "\n",
    "df_spark_worldtemperature = df_spark_worldtemperature.join(\n",
    "        df_spark_iso3166countries,\n",
    "        ['Country'],\n",
    "        how='left'\n",
    ") \\\n",
    "    .withColumnRenamed('Country', 'Country Name') \\\n",
    "    .withColumnRenamed('Alpha-3 code', 'Country') \\\n",
    "    .select(*worldtemperature_column_names, 'Country Name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 2.2.2.3: Unsemantic names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "column_rename = [\n",
    "    ('dt', 'Date'),\n",
    "    ('AverageTemperature', 'Average Temperature'),\n",
    "    ('AverageTemperatureUncertainty', 'Average Temperature Uncertainty'),\n",
    "]\n",
    "\n",
    "for k,v in column_rename:\n",
    "    df_spark_worldtemperature = df_spark_worldtemperature.withColumnRenamed(k, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 2.2.2.4: Out-of-range data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "## the data range of this data is 1743-2013, so we cannot match this data with the core immigration dataset by date\n",
    "## therefore, an average over time (e.g., average over the 20 year period from 1993-2013) per city is suitable\n",
    "df_spark_worldtemperature = df_spark_worldtemperature \\\n",
    "    .filter(F.col('Average Temperature').isNotNull()) \\\n",
    "    .filter(F.col('Date') >= F.lit('1993-01-01')) \\\n",
    "    .groupBy('City') \\\n",
    "    .agg(\n",
    "        F.mean('Average Temperature').alias('Average Temperature'),\n",
    "        F.first('Country').alias('Country'),\n",
    "        F.first('Country Name').alias('Country Name'),\n",
    "        F.first('Latitude').alias('Latitude'),\n",
    "        F.first('Longitude').alias('Longitude'),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Average Temperature</th>\n",
       "      <th>Country</th>\n",
       "      <th>Country Name</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Antwerp</td>\n",
       "      <td>10.451613</td>\n",
       "      <td>BEL</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>50.63N</td>\n",
       "      <td>3.80E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Araruama</td>\n",
       "      <td>24.189516</td>\n",
       "      <td>BRA</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>23.31S</td>\n",
       "      <td>42.82W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bangalore</td>\n",
       "      <td>25.080645</td>\n",
       "      <td>IND</td>\n",
       "      <td>India</td>\n",
       "      <td>12.05N</td>\n",
       "      <td>77.26E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Benxi</td>\n",
       "      <td>8.181452</td>\n",
       "      <td>CHN</td>\n",
       "      <td>China</td>\n",
       "      <td>40.99N</td>\n",
       "      <td>123.55E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cajamarca</td>\n",
       "      <td>16.931452</td>\n",
       "      <td>PER</td>\n",
       "      <td>Peru</td>\n",
       "      <td>7.23S</td>\n",
       "      <td>78.65W</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        City  Average Temperature Country Country Name Latitude Longitude\n",
       "0    Antwerp            10.451613     BEL      Belgium   50.63N     3.80E\n",
       "1   Araruama            24.189516     BRA       Brazil   23.31S    42.82W\n",
       "2  Bangalore            25.080645     IND        India   12.05N    77.26E\n",
       "3      Benxi             8.181452     CHN        China   40.99N   123.55E\n",
       "4  Cajamarca            16.931452     PER         Peru    7.23S    78.65W"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark_worldtemperature.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 2.2.3: U.S. City Demographic Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 2.2.3.1: Unsuitable types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# columns that should be IntegerType\n",
    "integer_type_columns = [\n",
    "    'Male Population', 'Female Population', 'Total Population', 'Number of Veterans', 'Foreign-born', 'Count',\n",
    "]\n",
    "for column in df_spark_uscitydemographic.columns:\n",
    "    if column in integer_type_columns:\n",
    "        df_spark_uscitydemographic = df_spark_uscitydemographic \\\n",
    "            .withColumn(column, df_spark_uscitydemographic[column].cast(IntegerType()))\n",
    "        \n",
    "# columns that should be FloatType\n",
    "float_type_columns = [\n",
    "    'Median Age', 'Average Household Size',\n",
    "]\n",
    "for column in df_spark_uscitydemographic.columns:\n",
    "    if column in float_type_columns:\n",
    "        df_spark_uscitydemographic = df_spark_uscitydemographic \\\n",
    "            .withColumn(column, df_spark_uscitydemographic[column].cast(FloatType()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 2.2.3.2: Unsemantic names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "column_rename = [\n",
    "    ('Number of Veterans', 'Veteran Population'),\n",
    "    ('Foreign-born', 'Foreign Born Population'),\n",
    "    ('Count', 'Race Count')\n",
    "]\n",
    "\n",
    "for k,v in column_rename:\n",
    "    df_spark_uscitydemographic = df_spark_uscitydemographic.withColumnRenamed(k, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 2.2.3.3: Redundant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "## every row for a given city has identical data in all columns except Race and Race Count,\n",
    "## so the table can be pivoted to have only one row per city\n",
    "column_names = df_spark_uscitydemographic.columns\n",
    "\n",
    "races = list(df_spark_uscitydemographic.select('Race').dropDuplicates().sort(F.asc('Race')).toPandas()['Race'])\n",
    "\n",
    "df_spark_uscitydemographic = df_spark_uscitydemographic\n",
    "for race in races:\n",
    "    df_spark_uscitydemographic = df_spark_uscitydemographic \\\n",
    "        .withColumn(race, F.when(F.col('Race') == race, F.col('Race Count')).otherwise(0))\n",
    "\n",
    "df_spark_uscitydemographic = df_spark_uscitydemographic \\\n",
    "    .groupBy('City', 'State') \\\n",
    "    .agg(\n",
    "        *map(lambda x: F.first(x).alias(x), filter(lambda y: y not in ['City', 'State', 'Race', 'Race Count'], column_names)),\n",
    "        *map(lambda x: F.max(x).alias(x + ' Population'), races),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Veteran Population</th>\n",
       "      <th>Foreign Born Population</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>American Indian and Alaska Native Population</th>\n",
       "      <th>Asian Population</th>\n",
       "      <th>Black or African-American Population</th>\n",
       "      <th>Hispanic or Latino Population</th>\n",
       "      <th>White Population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cincinnati</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>32.700001</td>\n",
       "      <td>143654</td>\n",
       "      <td>154883</td>\n",
       "      <td>298537</td>\n",
       "      <td>13699</td>\n",
       "      <td>16896</td>\n",
       "      <td>2.08</td>\n",
       "      <td>OH</td>\n",
       "      <td>3362</td>\n",
       "      <td>7633</td>\n",
       "      <td>133430</td>\n",
       "      <td>9121</td>\n",
       "      <td>162245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kansas City</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>33.400002</td>\n",
       "      <td>74606</td>\n",
       "      <td>76655</td>\n",
       "      <td>151261</td>\n",
       "      <td>8139</td>\n",
       "      <td>25507</td>\n",
       "      <td>2.71</td>\n",
       "      <td>KS</td>\n",
       "      <td>2749</td>\n",
       "      <td>7301</td>\n",
       "      <td>40177</td>\n",
       "      <td>44342</td>\n",
       "      <td>96113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lynchburg</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>28.700001</td>\n",
       "      <td>38614</td>\n",
       "      <td>41198</td>\n",
       "      <td>79812</td>\n",
       "      <td>4322</td>\n",
       "      <td>4364</td>\n",
       "      <td>2.48</td>\n",
       "      <td>VA</td>\n",
       "      <td>1024</td>\n",
       "      <td>2910</td>\n",
       "      <td>23271</td>\n",
       "      <td>2689</td>\n",
       "      <td>53727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Auburn</td>\n",
       "      <td>Washington</td>\n",
       "      <td>37.099998</td>\n",
       "      <td>36837</td>\n",
       "      <td>39743</td>\n",
       "      <td>76580</td>\n",
       "      <td>5401</td>\n",
       "      <td>14842</td>\n",
       "      <td>2.73</td>\n",
       "      <td>WA</td>\n",
       "      <td>3042</td>\n",
       "      <td>12341</td>\n",
       "      <td>4032</td>\n",
       "      <td>10836</td>\n",
       "      <td>58293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dayton</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>32.799999</td>\n",
       "      <td>66631</td>\n",
       "      <td>73966</td>\n",
       "      <td>140597</td>\n",
       "      <td>8465</td>\n",
       "      <td>7381</td>\n",
       "      <td>2.26</td>\n",
       "      <td>OH</td>\n",
       "      <td>2010</td>\n",
       "      <td>1885</td>\n",
       "      <td>57280</td>\n",
       "      <td>4945</td>\n",
       "      <td>86016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          City       State  Median Age  Male Population  Female Population  \\\n",
       "0   Cincinnati        Ohio   32.700001           143654             154883   \n",
       "1  Kansas City      Kansas   33.400002            74606              76655   \n",
       "2    Lynchburg    Virginia   28.700001            38614              41198   \n",
       "3       Auburn  Washington   37.099998            36837              39743   \n",
       "4       Dayton        Ohio   32.799999            66631              73966   \n",
       "\n",
       "   Total Population  Veteran Population  Foreign Born Population  \\\n",
       "0            298537               13699                    16896   \n",
       "1            151261                8139                    25507   \n",
       "2             79812                4322                     4364   \n",
       "3             76580                5401                    14842   \n",
       "4            140597                8465                     7381   \n",
       "\n",
       "   Average Household Size State Code  \\\n",
       "0                    2.08         OH   \n",
       "1                    2.71         KS   \n",
       "2                    2.48         VA   \n",
       "3                    2.73         WA   \n",
       "4                    2.26         OH   \n",
       "\n",
       "   American Indian and Alaska Native Population  Asian Population  \\\n",
       "0                                          3362              7633   \n",
       "1                                          2749              7301   \n",
       "2                                          1024              2910   \n",
       "3                                          3042             12341   \n",
       "4                                          2010              1885   \n",
       "\n",
       "   Black or African-American Population  Hispanic or Latino Population  \\\n",
       "0                                133430                           9121   \n",
       "1                                 40177                          44342   \n",
       "2                                 23271                           2689   \n",
       "3                                  4032                          10836   \n",
       "4                                 57280                           4945   \n",
       "\n",
       "   White Population  \n",
       "0            162245  \n",
       "1             96113  \n",
       "2             53727  \n",
       "3             58293  \n",
       "4             86016  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark_uscitydemographic.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 2.2.4 Normalize column names\n",
    "Some formats (including parquet) don't allow certain characters in column names, so these are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def normalize_column_names(df):\n",
    "    return df.select([F.col(col).alias(re.sub('[^0-9a-zA-Z$]+','', col.title())) for col in df.columns])\n",
    "  \n",
    "df_spark_i94immigration = normalize_column_names(df_spark_i94immigration)\n",
    "df_spark_worldtemperature = normalize_column_names(df_spark_worldtemperature)\n",
    "df_spark_uscitydemographic = normalize_column_names(df_spark_uscitydemographic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 3. Define the Data Model\n",
    "### 3.1 Conceptual Data Model\n",
    "The data model is a star schema.\n",
    "\n",
    "The fact table in the center of the star schema is the `immigration` table, in which each row represents a person immigrating into the US with a I-94 form. The dimension tables are `date`, `country` and `us_state`, with the foreign keys in the `immigration` table all using standardised formats.\n",
    "\n",
    "A star schema was chosen as it is a simple, well-understood convention that captures all of the data within the scope of this project.\n",
    "\n",
    "The below diagram was created on [https://dbdiagram.io](https://dbdiagram.io/d) - the source code can be viewed in `/images/er-diagram/source`.\n",
    "\n",
    "![ER Diagram](images/er-diagram/image.png)\n",
    "\n",
    "### 3.2 Mapping Out Data Pipelines\n",
    "Having completed the \"Cleaning\" step on the 3 core DataFrames, the next stage of the data pipeline is to generate the fact table and three dimension tables of the star schema.\n",
    "\n",
    "1. `immigration` fact table: this is generated from `df_spark_i94immigrations`, with a few columns renamed\n",
    "2. `date` dimension table: this is generated on the fly from a data range of `2016-01-01` to `2016-12-31`\n",
    "3. `us_state` dimension table: this is generated from `df_spark_uscitydemographic`, by rolling up such that there is one row per US state\n",
    "4. `country` dimension table: this is generated from `df_spark_worldtemperature`, by rolling up such that there is one row per country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 4: Run Pipelines to Model the Data \n",
    "### 4.1 Create the data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.1.1 `immigration` fact table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_spark_immigration_fact = df_spark_i94immigration \\\n",
    "    .withColumnRenamed('PortOfArrival', 'Port') \\\n",
    "    .withColumnRenamed('DateOfArrival', 'Date') \\\n",
    "    .withColumnRenamed('StateOfArrival', 'State')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>CountryCitizenship</th>\n",
       "      <th>CountryResidence</th>\n",
       "      <th>Port</th>\n",
       "      <th>Date</th>\n",
       "      <th>ModeOfTravel</th>\n",
       "      <th>State</th>\n",
       "      <th>DateOfDeparture</th>\n",
       "      <th>Age</th>\n",
       "      <th>VisaCategory</th>\n",
       "      <th>YearOfBirth</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Airline</th>\n",
       "      <th>FlightNumber</th>\n",
       "      <th>VisaType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>ECU</td>\n",
       "      <td>ECU</td>\n",
       "      <td>XXX</td>\n",
       "      <td>2016-04-29</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>37</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>1979</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ATL</td>\n",
       "      <td>2016-04-07</td>\n",
       "      <td>Air</td>\n",
       "      <td>AL</td>\n",
       "      <td>None</td>\n",
       "      <td>25</td>\n",
       "      <td>Student</td>\n",
       "      <td>1991</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>00296</td>\n",
       "      <td>F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>ALB</td>\n",
       "      <td>ALB</td>\n",
       "      <td>WAS</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>Air</td>\n",
       "      <td>MI</td>\n",
       "      <td>2016-08-25</td>\n",
       "      <td>55</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>1961</td>\n",
       "      <td>M</td>\n",
       "      <td>OS</td>\n",
       "      <td>93</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>ALB</td>\n",
       "      <td>ALB</td>\n",
       "      <td>NYC</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>Air</td>\n",
       "      <td>MA</td>\n",
       "      <td>2016-04-23</td>\n",
       "      <td>28</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>1988</td>\n",
       "      <td>None</td>\n",
       "      <td>AA</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>ALB</td>\n",
       "      <td>ALB</td>\n",
       "      <td>NYC</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>Air</td>\n",
       "      <td>MA</td>\n",
       "      <td>2016-04-23</td>\n",
       "      <td>4</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>2012</td>\n",
       "      <td>None</td>\n",
       "      <td>AA</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id CountryCitizenship CountryResidence Port        Date ModeOfTravel State  \\\n",
       "0   6                ECU              ECU  XXX  2016-04-29         None  None   \n",
       "1   7               None             None  ATL  2016-04-07          Air    AL   \n",
       "2  15                ALB              ALB  WAS  2016-04-01          Air    MI   \n",
       "3  16                ALB              ALB  NYC  2016-04-01          Air    MA   \n",
       "4  17                ALB              ALB  NYC  2016-04-01          Air    MA   \n",
       "\n",
       "  DateOfDeparture  Age VisaCategory  YearOfBirth Gender Airline FlightNumber  \\\n",
       "0            None   37     Pleasure         1979   None    None         None   \n",
       "1            None   25      Student         1991      M    None        00296   \n",
       "2      2016-08-25   55     Pleasure         1961      M      OS           93   \n",
       "3      2016-04-23   28     Pleasure         1988   None      AA        00199   \n",
       "4      2016-04-23    4     Pleasure         2012   None      AA        00199   \n",
       "\n",
       "  VisaType  \n",
       "0       B2  \n",
       "1       F1  \n",
       "2       B2  \n",
       "3       B2  \n",
       "4       B2  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark_immigration_fact.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.1.2 `date` dimension table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_spark_date_dim = spark.sql('SELECT sequence({start_date}, {end_date}, 60 * 60 * 24) as timestamp_seq'.format(\n",
    "    start_date=int(datetime(2016, 1, 1).timestamp()),\n",
    "    end_date=int(datetime(2016, 12, 31).timestamp())\n",
    ")) \\\n",
    "    .withColumn('timestamp', F.explode('timestamp_seq')) \\\n",
    "    .withColumn('Date', F.to_date(F.col('timestamp').cast(TimestampType()))) \\\n",
    "    .select('Date') \\\n",
    "    .withColumn('Day', F.dayofmonth(F.col('Date'))) \\\n",
    "    .withColumn('Month', F.month(F.col('Date'))) \\\n",
    "    .withColumn('Year', F.year(F.col('Date'))) \\\n",
    "    .withColumn('DayOfWeek', F.dayofweek(F.col('Date'))) \\\n",
    "    .withColumn('WeekOfYear', F.weekofyear(F.col('Date')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>WeekOfYear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>6</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>7</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-03</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Day  Month  Year  DayOfWeek  WeekOfYear\n",
       "0  2016-01-01    1      1  2016          6          53\n",
       "1  2016-01-02    2      1  2016          7          53\n",
       "2  2016-01-03    3      1  2016          1          53\n",
       "3  2016-01-04    4      1  2016          2           1\n",
       "4  2016-01-05    5      1  2016          3           1"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark_date_dim.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.1.3 `us_state` dimension table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# we can't roll 'Median Age' up from city level to state level, \n",
    "# but we can roll up 'Average Household Size' if we calculate 'Number of Households' as an intermediate step\n",
    "df_spark_uscitydemographic = df_spark_uscitydemographic \\\n",
    "    .withColumn('NumberOfHouseholds', (F.col('TotalPopulation') / F.col('AverageHouseholdSize')).cast(IntegerType()))\n",
    "\n",
    "df_spark_us_state_dim =  df_spark_uscitydemographic\\\n",
    "    .groupBy('StateCode') \\\n",
    "    .agg(\n",
    "        *map(\n",
    "            lambda x: F.first(x).alias(x),\n",
    "            ['State'],\n",
    "        ),\n",
    "        *map(\n",
    "            lambda x: F.sum(x).alias(x),\n",
    "            filter(\n",
    "                lambda y: y not in ['City', 'State', 'MedianAge', 'AverageHouseholdSize', 'StateCode'],\n",
    "                df_spark_uscitydemographic.columns,\n",
    "            ),\n",
    "        ),\n",
    "    ) \\\n",
    "    .withColumnRenamed('StateCode', 'Code') \\\n",
    "    .withColumnRenamed('State', 'Name') \\\n",
    "    .withColumn('AverageHouseholdSize', (F.col('TotalPopulation') / F.col('NumberOfHouseholds')).cast(FloatType())) \\\n",
    "    .sort(F.asc('Code'))\n",
    "\n",
    "# ensure there is at least one row per state\n",
    "df_spark_us_state_dim = df_spark_usstatesnames.select('Code').join(\n",
    "    df_spark_us_state_dim,\n",
    "    'Code',\n",
    "    how='left'\n",
    ") \\\n",
    "    .select(*df_spark_us_state_dim.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>Name</th>\n",
       "      <th>MalePopulation</th>\n",
       "      <th>FemalePopulation</th>\n",
       "      <th>TotalPopulation</th>\n",
       "      <th>VeteranPopulation</th>\n",
       "      <th>ForeignBornPopulation</th>\n",
       "      <th>AmericanIndianAndAlaskaNativePopulation</th>\n",
       "      <th>AsianPopulation</th>\n",
       "      <th>BlackOrAfricanAmericanPopulation</th>\n",
       "      <th>HispanicOrLatinoPopulation</th>\n",
       "      <th>WhitePopulation</th>\n",
       "      <th>NumberOfHouseholds</th>\n",
       "      <th>AverageHouseholdSize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>497248</td>\n",
       "      <td>552381</td>\n",
       "      <td>1049629</td>\n",
       "      <td>71543</td>\n",
       "      <td>52154</td>\n",
       "      <td>8084</td>\n",
       "      <td>28769</td>\n",
       "      <td>521068</td>\n",
       "      <td>39313</td>\n",
       "      <td>498920</td>\n",
       "      <td>443971</td>\n",
       "      <td>2.364184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AK</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>152945</td>\n",
       "      <td>145750</td>\n",
       "      <td>298695</td>\n",
       "      <td>27492</td>\n",
       "      <td>33258</td>\n",
       "      <td>36339</td>\n",
       "      <td>36825</td>\n",
       "      <td>23107</td>\n",
       "      <td>27261</td>\n",
       "      <td>212696</td>\n",
       "      <td>107832</td>\n",
       "      <td>2.770003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AZ</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>2227455</td>\n",
       "      <td>2272087</td>\n",
       "      <td>4499542</td>\n",
       "      <td>264505</td>\n",
       "      <td>682313</td>\n",
       "      <td>129708</td>\n",
       "      <td>229183</td>\n",
       "      <td>296222</td>\n",
       "      <td>1508157</td>\n",
       "      <td>3591611</td>\n",
       "      <td>1639715</td>\n",
       "      <td>2.744100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AR</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>286479</td>\n",
       "      <td>303400</td>\n",
       "      <td>589879</td>\n",
       "      <td>31704</td>\n",
       "      <td>62108</td>\n",
       "      <td>9381</td>\n",
       "      <td>22062</td>\n",
       "      <td>149608</td>\n",
       "      <td>77813</td>\n",
       "      <td>384733</td>\n",
       "      <td>238503</td>\n",
       "      <td>2.473256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA</td>\n",
       "      <td>California</td>\n",
       "      <td>12278281</td>\n",
       "      <td>12544179</td>\n",
       "      <td>24822460</td>\n",
       "      <td>928270</td>\n",
       "      <td>7448257</td>\n",
       "      <td>401386</td>\n",
       "      <td>4543730</td>\n",
       "      <td>2047009</td>\n",
       "      <td>9856464</td>\n",
       "      <td>14905129</td>\n",
       "      <td>8330600</td>\n",
       "      <td>2.979672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Code        Name  MalePopulation  FemalePopulation  TotalPopulation  \\\n",
       "0   AL     Alabama          497248            552381          1049629   \n",
       "1   AK      Alaska          152945            145750           298695   \n",
       "2   AZ     Arizona         2227455           2272087          4499542   \n",
       "3   AR    Arkansas          286479            303400           589879   \n",
       "4   CA  California        12278281          12544179         24822460   \n",
       "\n",
       "   VeteranPopulation  ForeignBornPopulation  \\\n",
       "0              71543                  52154   \n",
       "1              27492                  33258   \n",
       "2             264505                 682313   \n",
       "3              31704                  62108   \n",
       "4             928270                7448257   \n",
       "\n",
       "   AmericanIndianAndAlaskaNativePopulation  AsianPopulation  \\\n",
       "0                                     8084            28769   \n",
       "1                                    36339            36825   \n",
       "2                                   129708           229183   \n",
       "3                                     9381            22062   \n",
       "4                                   401386          4543730   \n",
       "\n",
       "   BlackOrAfricanAmericanPopulation  HispanicOrLatinoPopulation  \\\n",
       "0                            521068                       39313   \n",
       "1                             23107                       27261   \n",
       "2                            296222                     1508157   \n",
       "3                            149608                       77813   \n",
       "4                           2047009                     9856464   \n",
       "\n",
       "   WhitePopulation  NumberOfHouseholds  AverageHouseholdSize  \n",
       "0           498920              443971              2.364184  \n",
       "1           212696              107832              2.770003  \n",
       "2          3591611             1639715              2.744100  \n",
       "3           384733              238503              2.473256  \n",
       "4         14905129             8330600              2.979672  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark_us_state_dim.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.1.4 `country` dimension table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_spark_country_dim = df_spark_worldtemperature \\\n",
    "    .groupBy('Country') \\\n",
    "    .agg(\n",
    "        F.first('CountryName').alias('Name'),\n",
    "        F.mean('AverageTemperature').alias('AverageTemperature')\n",
    "    ) \\\n",
    "    .withColumnRenamed('Country', 'Code') \\\n",
    "    .sort(F.asc('Code'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>Name</th>\n",
       "      <th>AverageTemperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>14.537802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AGO</td>\n",
       "      <td>Angola</td>\n",
       "      <td>21.957661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALB</td>\n",
       "      <td>Albania</td>\n",
       "      <td>15.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ARE</td>\n",
       "      <td>United Arab Emirates (the)</td>\n",
       "      <td>27.322581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ARG</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>17.216620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Code                        Name  AverageTemperature\n",
       "0  AFG                 Afghanistan           14.537802\n",
       "1  AGO                      Angola           21.957661\n",
       "2  ALB                     Albania           15.875000\n",
       "3  ARE  United Arab Emirates (the)           27.322581\n",
       "4  ARG                   Argentina           17.216620"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark_country_dim.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.1.5 Persist model\n",
    "Write the model as parquet files to local and S3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "parquet_output_path = config['PARQUET']['OUTPUT_PATH']\n",
    "s3_output_path = 's3a://' + config['S3']['OUTPUT_PATH']\n",
    "\n",
    "for path in [parquet_output_path]: #, s3_output_path]:\n",
    "    df_spark_immigration_fact.write.mode('overwrite').parquet(path + '/immigration.parquet')\n",
    "    df_spark_date_dim.write.mode('overwrite').parquet(path + '/date.parquet')\n",
    "    df_spark_us_state_dim.write.mode('overwrite').parquet(path + '/us_state.parquet')\n",
    "    df_spark_country_dim.write.mode('overwrite').parquet(path + '/country.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 4.2 Data Quality Checks\n",
    "#### 4.2.1 Assert that all tables have data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "filenames = ['immigration', 'date', 'us_state', 'country']\n",
    "\n",
    "for filename in filenames:\n",
    "    df = spark.read.parquet('./models/' + filename + '.parquet')\n",
    "    assert df.count() > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2.2 Assert foreign key constraints\n",
    "The example below asserts that the `State` column in the `immigration` fact table is a valid foreign key into the `us_state` dimension table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "fact_immigration = spark.read.parquet('./models/immigration.parquet')\n",
    "dim_us_state = spark.read.parquet('./models/us_state.parquet')\n",
    "\n",
    "fact_immigration_states = list(fact_immigration.select('State').dropDuplicates().filter(F.col('State').isNotNull()).toPandas()['State'])\n",
    "dim_country_states = list(dim_us_state.select('Code').toPandas()['Code'])\n",
    "\n",
    "for state in fact_immigration_states:\n",
    "    assert state in dim_country_states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The rest of the foreign keys could be checked in a similar way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 4.3 Data dictionary \n",
    "`immigration` fact table:\n",
    "\n",
    "| Column             | Type   | Description |\n",
    "| ------------------ | ------ | ----------- |\n",
    "| Id                 | int    | Id (PK) |\n",
    "| Port               | string | Port of Entry |\n",
    "| State              | string | State of Entry (as: 2 character code) (FK to `us_state` table) |\n",
    "| Date               | date   | Date of Entry (FK to `date` table) |\n",
    "| DateOfDeparture    | date   | Date of Departure (FK to `date` table) |\n",
    "| CountryCitizenship | string | Country of Citizenship of Immigrant (as: ISO-3166 Alpha-3) (FK to `country` table) |\n",
    "| CountryResidence   | string | Country of Residence of Immigrant (as: ISO-3166 Alpha-3) (FK to `country` table) |\n",
    "| ModeOfTravel       | string | Mode of Travel (as: 1 = Air, 2 = Sea, 3 = Land, 9 = Not Reported) |\n",
    "| Age                | int    | Age of Immigrant (as: years) |\n",
    "| YearOfBirth        | int    | Year of Birth of Immigrant |\n",
    "| Gender             | string | Gender of Immigrant (as: M, F) |\n",
    "| Airline            | string | Airline of Travel (if applicable) |\n",
    "| FlightNumber       | string | Flight Number (if applicable) |\n",
    "| VisaCategory       | string | Visa Category |\n",
    "| VisaType           | string | Visa Type |\n",
    "\n",
    "\n",
    "`date` dimension table:\n",
    "\n",
    "| Column             | Type   | Description |\n",
    "| ------------------ | ------ | ----------- |\n",
    "| Date       | date | Date (PK) |\n",
    "| Day        | int  | Day (of Month) |\n",
    "| Month      | int  | Month |\n",
    "| Year       | int  | Year |\n",
    "| DayOfWeek  | int  | Day of Week |\n",
    "| WeekOfYear | int  | Week of Year |\n",
    "\n",
    "\n",
    "`country` dimension table:\n",
    "\n",
    "| Column             | Type   | Description |\n",
    "| ------------------ | ------ | ----------- |\n",
    "| Code               | string | Country Code (as: ISO-3166 Alpha-3) (PK) |\n",
    "| Name               | string | Country Name |\n",
    "| AverageTemperature | int    | Average Temperature of the Country between 1993 and 2013 |\n",
    "\n",
    "\n",
    "`us_state` dimension table:\n",
    "\n",
    "| Column                                  | Type   | Description |\n",
    "| --------------------------------------- | ------ | ----------- |\n",
    "| Code                                    | string | State Code (PK) |\n",
    "| Name                                    | string | State Name |\n",
    "| TotalPopulation                         | int    | Total Population of the State |\n",
    "| MalePopulation                          | int    | Male Population of the State |\n",
    "| FemalePopulation                        | int    | Female Population of the State |\n",
    "| VeteranPopulation                       | int    | Veteran Population of the State |\n",
    "| ForeignBornPopulation                   | int    | Foreign-born Population of the State |\n",
    "| AmericanIndianAndAlaskaNativePopulation | int    | American Indian and Alaska Native Population of the State |\n",
    "| AsianPopulation                         | int    | Asian Population of the State |\n",
    "| BlackOrAfricanAmericanPopulation        | int    | Black or African-American Population of the State |\n",
    "| HispanicOrLatinoPopulation              | int    | Hispanic or Latino Population of the State |\n",
    "| WhitePopulation                         | int    | White Population of the State |\n",
    "| AverageHouseholdSize                    | int    | Average Household Size of the State |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 5: Further Questions\n",
    "#### Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "- **[Apache Spark](https://spark.apache.org/)**: chosen as it is a high performance, simple to use, industry standard engine for data lake processing. It allowed performant code to be written with easy-to-read syntax, and comes with out-of-the-box integrations with Jupyter, which was perfect for a project such as this\n",
    "- **[Parquet](https://parquet.apache.org/)**: the data model is stored as Parquet files, which is a standard format for Hadoop-based systems (such as Spark) since it provides high compression and high performance encoding for columnar storage\n",
    "- **[AWS S3](https://aws.amazon.com/s3/)**: the data model is stored in S3 (as well as locally) to unlock the power of other cloud-based tools for data analysis, for example, being ETL-ed into a [Redshift](https://aws.amazon.com/redshift/) cluster using an [Airflow](https://airflow.apache.org/), as demostrated in the \"5 - Data Pipelines with Airflow\" project\n",
    "\n",
    "#### Propose how often the data should be updated and why.\n",
    "The data should be updated every month, as the core data set is published as a monthly file.\n",
    "\n",
    "#### Write a description of how you would approach the problem differently under the following scenarios:\n",
    "##### The data was increased by 100x\n",
    "The Spark cluster on which the ETL runs would need to be scaled horizontally by adding more nodes. Furthermore, it may make sense to process the data in smaller timesliced batches.\n",
    "\n",
    "##### The data populates a dashboard that must be updated on a daily basis by 7am every day\n",
    "The pipeline could be coordinated by an Airflow instance running on the Spark cluster, scheduled such that it ran daily in the hour before 7am. \n",
    "\n",
    "##### The database needed to be accessed by 100+ people\n",
    "Since the data is persisted in S3, it can be accessed by as many people as necessary. Access to the S3 data itself can be managed through [AWS IAM](https://aws.amazon.com/iam/) roles, while access to the data via a 3rd-party-tool tool (e.g., a [Tableau](https://www.tableau.com/) instance connected to the S3 bucket) can be controlled by the 3rd-party-tool's access controls."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
